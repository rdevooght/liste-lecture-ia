## Qu'est-ce que l'IA?

[What is AI?](https://www.technologyreview.com/2024/07/10/1094475/what-is-artificial-intelligence-ai-definitive-guide/) (MIT Technology Review, Juillet 2024):
Un long article pour présenter les points de vue très différents que des expert·es ont sur ce qu'est l'IA.
Difficile d'en tirer une conclusion si ce n'est qu'il y a des désaccords fondamentaux et qu'ils reflètent davantage des différences d'idéologies que de maîtrise du sujet.

## Utilisation

19% des français utilisent chatgpt: [Un Français sur cinq a déjà utilisé ChatGPT - Odoxa](https://www.odoxa.fr/sondage/un-francais-sur-cinq-a-deja-utilise-chatgpt/)

Les belges sont moins optimistes que la moyenne par rapport à l'IA:
41% des belges pensent que l'IA aura un impact positif sur leur vie, contre 61% en moyenne dans le monde.
([Global opinions and expectations about AI](https://www.ipsos.com/sites/default/files/ct/news/documents/2022-01/Global-opinions-and-expectations-about-AI-2022.pdf), enquête Ipsos, janvier 2022)

Il semble que mieux connaître le fonctionnement des IA ferait qu'on l'utilise moins
([The Conversation](https://theconversation.com/knowing-less-about-ai-makes-people-more-open-to-having-it-in-their-lives-new-research-247372), janvier 2025).
Un résultat surprenant, et je n'ai pas accès à l'article original pour en savoir plus.

## Copyrigth

[Meta pirate du contenu pour entrainer son IA](https://fingfx.thomsonreuters.com/gfx/legaldocs/lbvgjdkdopq/META%20COPYRIGHT%20LAWSUIT%20libgen.pdf) (Reuters, janvier 2025):
Grâce aux communications internes de Meta, obtenues dans le cadre d'un procès concernant les données d'entraînement de son IA,
il apparaît que Meta a utilisé la plus grande base de données de livres piratés (LibGen) pour entraîner son IA.

> Meta knowingly used a version of LibGen for which Mr. Bashlykov had written a script
> “to remove copyright information,” including “the word copyright, the word ‘acknowledgments,’
> and matches upon phrases and lines in... the book that did that”

Tout cela avec la validation de Mark Zuckerberg.

> memo to Meta’s AI decision-makers noting that after “escalation to MZ,” Meta’s AI team “has been approved to use LibGen”

[To Whom Does the World Belong?](https://www.bostonreview.net/articles/to-whom-does-the-world-belong/) (Boston Review, décembre 2024):
A qui appartient le contenu généré par une IA? Les développeurs, les entreprises, les utilisateurs, les IA elles-mêmes, tout le monde?
Peut-être que la notion de propriété intellectuelle n'est pas adaptée au contenu généré par une IA.

> we can’t afford to wait for all the money and power to accrue to Silicon Valley and then get together to have a big think about redistributing.
> We need to consider these rules now and work immediately toward a new intellectual property framework

Cette question a une grande importance, les IA génératives peuvent générer de la propriété intellectuelle plus rapidement que jamais, et d'après une étude de 2010,
"The value of intellectual property exceeds 65% for Fortune 500 companies and exceeds 90% for certain technology-based companies within the list"
(cité depuis [The Value of Intellectual Property](https://www.heerlaw.com/value-intellectual-property)).

## Travail caché

Sur le travail d'annotation:

- [AI Is a Lot of Work](https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots) (The Verge, juin 2023)
- [OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic](https://time.com/6247678/openai-chatgpt-kenya-workers/) (Time, janvier 2023)

[Becoming a chatbot](https://www.theguardian.com/technology/2022/dec/13/becoming-a-chatbot-my-life-as-a-real-estate-ais-human-backup)
(The Guardian, décembre 2022):
Derrière un chatbot pour une agence immobilière se cachaient 60 personnes qui relisaient les réponses du chatbot et prenaient le relais quand nécessaire.

## Impacts environnementaux

### Consommation électrique

[Powering Artificial Intelligence](https://www.deloitte.com/content/dam/assets-shared/docs/about/2024/powering-artificial-intelligence.pdf) (Deloitte, novembre 2024):
Deloitte estime que la consommation électrique liée à l'IA a augmenté de 47% par an entre 2020 et 2023, et devrait continuer à augmenter de 28% à 44% par an pendant les années à venir.

[Data center emissions probably 662% higher than big tech claims](https://www.theguardian.com/technology/2024/sep/15/data-center-gas-emissions-tech) (The Guardian, septembre 2024):
Les déclarations des GAFAM sur leur empreinte carbone sont trompeuses car elles se basent sur l'achat massif de certificats verts pour compenser leur émissions réelles.
Les emissions réelles de leurs data centers sont beaucoup plus élevées: probablement 3x plus pour Google, 21x plus pour Microsoft et 3000x plus pour Meta.
On parle ici de toutes les activités des data centers, pas seulement celles liées à l'IA.

[AI needs so much power, it's making yours worse](https://www.bloomberg.com/graphics/2024-ai-power-home-appliances/) (Bloomberg, décembre 2024):
Les data centers semblent créer des distorsions sur le réseau électrique environnant (en ajoutant des harmoniques sur le courant alternatif), ce qui peut endommager les appareils électriques des habitants.

Ce ne sont pas les impacts environnementaux qui vont freiner les géants de l'IA.
L'ancien CEO de google le dit clairement:
"We're not going to hit the climate goals anyway because we're not organized to do it [...] I'd rather bet on AI solving the problem, than constraining it and having the problem."
(Eric Schmidt, cité depuis [Mashable](https://mashable.com/article/former-google-ceo-invest-ai-despite-climate-concerns), octobre 2024)

## Hallucinations

## Capacités

## Sécurité & Alignement
Quand les développeurs d'IA parlent des risques liés à l'IA, iels parlent souvent de ce qu'on appelle le problème "d'alignement".
C'est à dire, comment s'assurer que l'IA fasse effectivement ce que l'on veut qu'elle fasse, et pas autre chose.
Plus on donnera de capacité aux IA d'effectuer des actions et de prendre des décisions ayant un impact réel, plus ce risque sera important.
Malheureusement, il semble que plus les IA deviennent performantes, plus il est compliqué de comprendre comment elles fonctionnent et donc de s'assurer qu'elles sont alignées.

[AI Safety for Fleshy Humans](https://aisafety.dance) (Nicky Case & Hack Club):
Long article (encore en cours d'écriture) sur les risques liés à l'alignement de l'IA.

[o1 et Claude sont-ils capablent de nous manipuler](https://www.youtube.com/watch?v=cw9wcNKDOtQ) (Monsieur Phi, décembre 2024):
Vidéo vulgarisant les résultats des deux articles suivants:

- [Frontier Models are Capable of In-context Scheming](https://static1.squarespace.com/static/6593e7097565990e65c886fd/t/67869dea6418796241490cf0/1736875562390/in_context_scheming_paper_v2.pdf) ([synthèse](https://www.apolloresearch.ai/research/scheming-reasoning-evaluations))
- [Alignment faking in large language models](https://arxiv.org/pdf/2412.14093) ([synthèse](https://www.anthropic.com/research/alignment-faking))

Ces articles observent que Les LLMs actuels montrent des comportement problématiques quand mis face à des objectifs contradictoires. Par exemple:

- Sandbagging: l'IA bride ses capacités quand on indique que des capacitées plus élevées mèneront à un réentrainement
- Alignment faking: l'IA répond de manière différente dans un environnement de test que dans un environnement de production

### Critique du problème d'alignement
De nombreuses personnes critiques de l'IA considèrent que le problème d'alignement est une diversion
qui nous empêche de parler des problèmes actuels liés aux IA, et qui véhicule l'idée que les IA "superintelligentes" sont imminentes, ce qui est très controversé.
